# ğŸ¬ Media Scraper â€” Demo Walkthrough

This demo showcases the **Media Scraper system**: a queue-based, high-concurrency scraper that can handle **~5000 concurrent requests** on **1 CPU / 1 GB RAM**.

The following steps explain **how to run**, **which URLs to visit**, and **what each part demonstrates**.

---

## ğŸ§­ Step-by-Step Demo Flow

### ğŸ§± Step 1 â€” Start the Entire System

```bash
make up
```

**Purpose:**

- Builds all Docker services (`api`, `worker`, `redis`, `postgres`, `landing`).
- Waits until `/health` returns OK.

**Demonstrates:**
âœ… One-command reproducible setup.
âœ… API stability under startup stress.
âœ… Full CI/CD readiness.

---

### ğŸŒ Step 2 â€” Check the Core URLs

| URL                                                                           | Purpose            | Description                                                                                               |
| ----------------------------------------------------------------------------- | ------------------ | --------------------------------------------------------------------------------------------------------- |
| [http://localhost:4000/health](http://localhost:4000/health)                  | ğŸ©º Health Check    | Confirms that API, PostgreSQL, and Redis are connected. Returns `{ ok: true }`.                           |
| [http://localhost:4000/metrics](http://localhost:4000/metrics)                | ğŸ“ˆ System Metrics  | Shows CPU %, memory, Redis latency, event-loop lag, and queue stats (waiting, active, completed, failed). |
| [http://localhost:3000](http://localhost:3000)                                | ğŸ–¼ï¸ Landing Page    | Displays scraped images/videos using `/media` API. Supports pagination, filtering, and search.            |
| [http://localhost:3000/dashboard/metrics](http://localhost:4000/admin/queues) | ğŸ”„ Queue Dashboard | Visualizes BullMQ jobs (waiting, active, completed, failed). Optional but great for demo.                 |

---

### ğŸš€ Step 3 â€” Trigger Scraping via API (smoke test)

```bash
curl -u admin:admin -X POST http://localhost:4000/scrape   -H "Content-Type: application/json"   -d '{"urls":["https://wikipedia.org","https://developer.mozilla.org"]}'
```

**Purpose:**

- Test `/scrape` endpoint with Basic Auth.
- Validate input via Zod.
- Receive `HTTP 202 Accepted` instantly (as jobs are queued asynchronously).

**Demonstrates:**
âœ… Non-blocking Fastify API.
âœ… Instant 202 response even under heavy concurrency.
âœ… Queue-first architecture (API does not scrape directly).

---

### ğŸ§  Step 4 â€” Run Smoke Test

```bash
make smoke
```

**Purpose:**

- Validate API correctness and queue connection.
- Ensure `/scrape` works before load testing.

**Demonstrates:**
âœ… System readiness & health under low load.

---

### ğŸ”¥ Step 5 â€” Run Load Tests (Performance Validation)

```bash
make load
```

**This runs two scenarios:**

| File                            | Scenario                      | Goal                                             |
| ------------------------------- | ----------------------------- | ------------------------------------------------ |
| `load/02_burst_5k_requests.yml` | 5000 concurrent HTTP requests | Stress-test API concurrency (burst test).        |
| `load/03_batch_5k_urls.yml`     | 500 requests Ã— 10 URLs each   | Verify large payload handling (5000 URLs total). |

**Reports generated:**

```
load/report-burst.json
load/report-batch.json
```

**Demonstrates:**
âœ… APIâ€™s ability to accept and respond to 5000 concurrent requests.
âœ… System stability under 1 CPU / 1 GB RAM constraint.
âœ… Queue buffering and deferred processing.

---

### ğŸ“Š Step 6 â€” View Performance Metrics

**Look for:**

- `p95 latency < 100 ms`
- `100% 202 responses`
- `no 5xx`
- memory < 1 GB

Then check live metrics:

```bash
curl -u admin:admin http://localhost:4000/metrics | jq
```

or open in browser:

http://localhost:3000/dashboard/metrics

**Demonstrates:**
âœ… Healthy event loop (lag < 10 ms).
âœ… Controlled queue backlog growth.
âœ… Consistent resource usage.

---

### ğŸ§© Step 7 â€” View Scraped Results on Landing Page

Open:

```
http://localhost:3000
```

**Features to demo:**

- Grid of images/videos
- Pagination
- Filter by type (`image`, `video`)
- Search by keyword

**Demonstrates:**
âœ… Frontend integration with `/media` endpoint.
âœ… Data persistence in PostgreSQL.

---

## ğŸ§® Internal Architecture Explained

```
Client â†’ Fastify API â†’ Redis Queue â†’ Worker (Puppeteer + Prisma) â†’ PostgreSQL
```

- **API**: lightweight, responds instantly with `202`
- **Queue**: buffers jobs, isolates load from scraper
- **Worker**: executes scraping asynchronously using Puppeteer
- **Database**: stores unique media URLs per page

---

## ğŸ§± Version Evolution

| Version                           | Summary                                                                                                                          | Result                                |
| --------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------- |
| **v1 (Express + queueMicrotask)** | Added microtask buffering to return fast, but API still bottlenecked under 3k+ concurrent requests due to event-loop saturation. | âŒ Not scalable                       |
| **v2 (Fastify + BullMQ)**         | Replaced Express with Fastify, added jobBuffer + backpressure handling, separated scraping to worker.                            | âœ… Stable at 5000 concurrent requests |
| **v2.1 (Optimized Puppeteer)**    | Reused Chromium instance, disabled GPU/sandbox, tuned page concurrency.                                                          | âœ… Efficient CPU/memory use           |

---

## ğŸ§© Why This Demo Matters

This project demonstrates **event-loop isolation and queue-based scalability** â€” how to design a Node.js service that can:

- Accept massive concurrency
- Respond instantly (202)
- Offload heavy tasks (scraping)
- Maintain reliability within 1 CPU / 1 GB RAM

Itâ€™s a reproducible model for **high-throughput, low-latency systems** in limited-resource environments.

---

### ğŸ‘¤ Author

**Le Thanh Phuoc**
Software Engineer
